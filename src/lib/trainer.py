#
#
#   Trainer
#
#

import os
import math
import GPUtil
import cpuinfo
import platform
import numpy as np

from datetime import datetime
from keras.utils import to_categorical

from . import trackers
from .logger import get_logger
from .utils.path import chdir
from .utils.timing import ElapsedTimeCalculator
from .utils.io_utils import save_to_json
from .services import DownloadManager
from .utils.text_utils import humanize_bytes
from .utils.data import Subset, DataLoader, get_approximate_nbytes


class Trainer:
    """
    Entrypoint to run experiment given an experiment, a model, a dataset, a training and a tracking.
    The run method will create a directory with the following structure:
    trainings_path/
    └── {{dataset.name}}/
        ├── executions_dirname/
        │   └── {{datetime ~ execution_format}}/  # datetime when run is called
        │       ├── metrics.json  # metrics, HW details and elapsed times
        │       └── artifacts
        │          └── ... # model weights/parameters, trainings artifacts (e.g callbacks),
        │                     preprocessors pipeline, etc ...
        └── trackings_dirname/  # artifacts generated by each tracker
            └── {{tracking.trackers[i].name}}/

    Parameters
    ----------
    trainings_path: str, optional
        Path with the directory where the experiments are run.
    executions_dirname: str, optional
        Directory name where an execution for a dataset is saved.
    trackings_dirname: str, optional
        Directory name where an execution for a dataset is tracked.
    execution_format: str, optional
        Formatting for executions, it can contain named formatting options, which will be filled with
        the values of datetime, model_name, dataset_name and experiment_name.
    artifacts_dirname: str, optional
        Directory name where artifacts are saved (saved model, saved preprocessors, etc ...)
    hdf5_datasets_dir: str, optional
        Directory to read and save HDF5 optimized datasets.
    """

    def __init__(self, trainings_path="trainings", executions_dirname="executions",
                 trackings_dirname="trackings", execution_format="{datetime:%H-%M-%S--%d-%m-%Y}__{model_name}",
                 artifacts_dirname="artifacts", download_dir="downloads",
                 extract_dir=None, force_download=False, force_extraction=False):
        self.trainings_path = trainings_path
        self.executions_dirname = executions_dirname
        self.trackings_dirname = trackings_dirname
        self.execution_format = execution_format
        self.artifacts_dirname = artifacts_dirname

        self.dl_manager = DownloadManager(download_dir, extract_dir=extract_dir,
                                          force_download=force_download,
                                          force_extraction=force_extraction)

        self.logger = get_logger(prefix=self)


    def train(self, experiment, model, dataset, training, tracking):
        """
        Run experiment generating outputs.

        Parameters
        ----------
        experiment: core.experiment.Experiment
        model: core.model.model
        dataset: core.dataset.Dataset
        training: core.training.Training
        tracking: core.tracking.Tracking

        Attributes
        ----------
        last_execution_path_: str
            Execution path for the last train
        """

        elapsed_time_calc = ElapsedTimeCalculator()
        execution_id = self.execution_format.format(datetime=datetime.now(), model_name=model.name,
                                                    dataset_name=dataset.name, experiment_name=experiment.name)

        self.logger.info("Running experiment: {} ...".format(execution_id))

        # CREATE DIRECTORIES TO STORE TRAININGS EXECUTIONS

        trainings_dataset_path = os.path.join(self.trainings_path, dataset.name)
        trainings_dataset_trackings_path = os.path.join(trainings_dataset_path, self.trackings_dirname)

        self.last_execution_path_ = os.path.join(trainings_dataset_path, self.executions_dirname, execution_id)

        trainings_dataset_execution_artifacts_path = os.path.join(self.last_execution_path_,
                                                                  self.artifacts_dirname)

        os.makedirs(self.last_execution_path_)
        os.makedirs(trainings_dataset_execution_artifacts_path)
        os.makedirs(trainings_dataset_trackings_path, exist_ok=True)

        self.logger.info("The execution will be saved in the following directory: {}".format(
                         self.last_execution_path_))
        self.logger.info("Tracking information will be saved in the following directory: {}".format(
                         trainings_dataset_trackings_path))

        # RETRIEVE PLATFORM DETAILS

        cpu_info = cpuinfo.get_cpu_info()

        gpus_info = []
        for gpu in GPUtil.getGPUs():
            gpus_info.append({
                "name": gpu.name,
                "memory": gpu.memoryTotal
            })

        platform_details = {
            "python_version": platform.python_version(),
            "python_compiler": platform.python_compiler(),
            "platform": platform.platform(),
            "system": platform.system(),
            "node": platform.node(),
            "architecture": platform.architecture()[0],
            "processor": platform.processor(),
            "cpu": {
                "brand": cpu_info["brand"],
                "cores": cpu_info["count"]
            },
            "gpu": gpus_info
        }

        for name, key in zip(("Python version", "Platform"), ("python_version", "platform")):
            self.logger.debug("{}: {}".format(name, platform_details[key]))

        self.logger.debug("Found {} GPUs".format(len(gpus_info)))

        # DEFINE TRACKER TO STORE METRICS AND SAVE THEM TO JSON LATER

        history_tracker = trackers.History()
        tracking.trackers.add(history_tracker)

        # START TRACKING

        tracking.trackers.start(run_name=execution_id, logdir=trainings_dataset_trackings_path)

        # LOG TRACKING AND MODEL PARAMETERS

        tracking.trackers.log_params(tracking.params)
        tracking.trackers.log_params(model.parameters)

        # DOWNLOAD DATA

        self.logger.info("Downloading and preparing data")
        with elapsed_time_calc("dataset_download_and_prepare") as elapsed:
            dataset.dataset.download_and_prepare(self.dl_manager)

        self.logger.debug("Downloading and preparing data took {:.2f}".format(elapsed.s))

        # LOG DATASET PROPERTIES

        dataset_info = dataset.dataset.info()

        self.logger.debug("Dataset Features: {}".format(dataset_info.features))
        self.logger.debug("Dataset Labels: {}".format(dataset_info.labels))


        nbytes = get_approximate_nbytes(dataset.dataset)
        self.logger.debug("Full Dataset Samples: {}".format(len(dataset.dataset)))
        self.logger.debug("Full Dataset Memory Usage (approx): {}".format(humanize_bytes(nbytes)))

        # SPLIT DATASET INTO TRAIN AND TEST

        train_samples = dataset.samples.train
        test_samples = dataset.samples.test

        if 0.0 < train_samples < 1.0:
            train_samples = math.floor(train_samples * len(dataset.dataset))
        if 0.0 < test_samples < 1.0:
            test_samples = math.floor(test_samples * len(dataset.dataset))

        train_indices = np.arange(train_samples)
        test_indices  = np.arange(train_samples, train_samples + test_samples)

        indices = np.arange(len(dataset.dataset))

        if dataset.shuffle:
            indices = np.random.permutation(indices)

        train_indices = indices[:train_samples]
        test_indices = indices[train_samples:(train_samples + test_samples)]

        train_subset = Subset(dataset.dataset, train_indices)
        test_subset  = Subset(dataset.dataset, test_indices)

        # LOAD DATA

        load_data_by_chunks = dataset.chunk_size is not None

        if load_data_by_chunks:
            train_loader = DataLoader(train_subset, batch_size=dataset.chunk_size, drop_last=False)
            test_loader  = DataLoader(test_subset, batch_size=dataset.chunk_size, drop_last=False)
        else:
            self.logger.info("Loading data into memory")

            with elapsed_time_calc("load_data_into_memory") as elapsed:
                train_data = DataLoader(train_subset, batch_size=len(dataset.dataset), drop_last=False, verbose=True)[0]
                test_data = DataLoader(test_subset, batch_size=len(dataset.dataset), drop_last=False, verbose=True)[0]

            self.logger.debug("Loading data into memory took {:.2f}s".format(elapsed.s))

        # PREPROCESS DATA

        self.logger.info("Fitting preprocessing pipeline using training data ({})".format(dataset.pipeline))

        if load_data_by_chunks:
            dataset.pipeline.fit_generator(train_loader)
        else:
            with elapsed_time_calc("fit_pipeline") as elapsed:
                dataset.pipeline.fit(train_data[0], train_data[1])

            self.logger.debug("Fit pipeline took {:.2f}s".format(elapsed.s))

        def normalizer(data):
            """
            Preprocess batch of data (X, y):
                1. Preprocessing
                2. Convert to one-hot encoding if needed
            """
            data = list(data)  # make sure data is a list and not a tuple (can't modify tuples)
            data[0] = dataset.pipeline.transform(data[0])

            if dataset.one_hot:
                data[1] = to_categorical(data[1], dataset_info.labels.num_classes)

            return data

        self.logger.info("Preprocessing data ({})".format(dataset.pipeline))

        if load_data_by_chunks:
            train_loader.transform_func = normalizer
            test_loader.transform_func = normalizer
        else:
            with elapsed_time_calc("transform_data") as elapsed:
                train_data = normalizer(train_data)
                test_data = normalizer(test_data)

            self.logger.debug("Transforming data took {:.2f}s".format(elapsed.s))

        # FIT MODEL

        self.logger.info("Fitting model using training data")

        if load_data_by_chunks:
            with elapsed_time_calc("fit_model_generator") as elapsed, chdir(trainings_dataset_execution_artifacts_path):
                train_metrics = model.model.fit_generator(train_loader, **training.parameters)

            self.logger.debug("Fit model generator took {:.2f}s".format(elapsed.s))
        else:
            with elapsed_time_calc("fit_model") as elapsed, chdir(trainings_dataset_execution_artifacts_path):
                train_metrics = model.model.fit(train_data[0], train_data[1], **training.parameters)

            self.logger.debug("Fit model took {:.2f}s".format(elapsed.s))

        for metric_name, metric_value in train_metrics.items():
            self.logger.info("Results for {} -> mean={:.2f}, min={:.2f}, max={:.2f}".format(metric_name,
                                                                                            np.mean(metric_value),
                                                                                            np.min(metric_value),
                                                                                            np.max(metric_value)))
        tracking.trackers.log_metrics(train_metrics)

        # EVALUATE MODEL

        self.logger.info("Evaluating model using test data")

        if load_data_by_chunks:
            with elapsed_time_calc("evaluate_model_generator") as elapsed:
                test_metrics = model.model.evaluate_generator(test_loader)

            self.logger.debug("Evaluating model with generator took {:.2f}".format(elapsed.s))
        else:
            with elapsed_time_calc("evaluate_model") as elapsed:
                test_metrics = model.model.evaluate(test_data[0], test_data[1])

            self.logger.debug("Evaluating model took {:.2f}s".format(elapsed.s))

        for metric_name, metric_value in test_metrics.items():
            self.logger.info("test_{}={}".format(metric_name, metric_value))

        tracking.trackers.log_metrics(test_metrics, prefix="test_")

        # SAVE MODEL

        self.logger.info("Saving model")

        with elapsed_time_calc("save_model") as elapsed:
            model.model.save(trainings_dataset_execution_artifacts_path)

        self.logger.debug("Saving model took {:.2f}s".format(elapsed.s))

        # SAVE PIPELINE

        self.logger.info("Saving pipeline")

        with elapsed_time_calc("save_pipeline") as elapsed:
            dataset.pipeline.save(os.path.join(trainings_dataset_execution_artifacts_path, "pipeline.pkl"))

        self.logger.debug("Saving pipeline took {:.2f}s".format(elapsed.s))

        # SAVE METRICS

        self.logger.info("Saving metrics to JSON file")
        metrics = dict(
            elapsed=elapsed_time_calc.times,
            metrics=history_tracker.metrics,
            platform=platform_details
        )
        metrics_path = os.path.join(self.last_execution_path_, "metrics.json")
        save_to_json(metrics_path, metrics)

        self.logger.info("Metrics, platform information and elapsed times saved to {} file".format(metrics_path))

        tracking.trackers.end()
