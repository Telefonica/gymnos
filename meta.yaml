models:
  dummy:
    _target_: gymnos.dummy.__model__.DummyTrainer
  vision.object_detection.yolov4:
    classes: ???
    batch_size: 64
    subdivisions: 16
    num_epochs: 300
    learning_rate: 0.001
    gpus: -1
    num_workers: 0
    optimizer: ADAM
    log_interval_frequency: 20
    train_split: 0.6
    val_split: 0.2
    test_split: 0.2
    seed: 0
    momentum: 0.949
    decay: 0.0005
    burn_in: 1000
    steps:
    - 400000
    - 450000
    width: 608
    height: 608
    mixup: null
    letter_box: false
    jitter: 0.2
    hue: 0.1
    saturation: 1.5
    exposure: 1.5
    flip: true
    blur: false
    gaussian: false
    boxes: 60
    num_anchors: 3
    cutmix: false
    mosaic: true
    use_pretrained: false
    _target_: gymnos.vision.object_detection.yolov4.trainer.Yolov4Trainer
  vision.image_classification.transfer_efficientnet:
    classes: ???
    num_workers: 0
    batch_size: 32
    num_epochs: 30
    gpus: -1
    train_split: 0.6
    val_split: 0.2
    test_split: 0.2
    accelerator: ddp
    _target_: gymnos.vision.image_classification.transfer_efficientnet.trainer.TransferEfficientNetTrainer
  generative.image_generation.dcgan:
    batch_size: 64
    num_epochs: 100
    num_workers: 0
    latent_size: 128
    num_channels: 3
    generator_depth: 64
    discriminator_depth: 64
    log_images_interval: 5
    generator_learning_rate: 0.0002
    discriminator_learning_rate: 0.0002
    gpus: -1
    beta1: 0.5
    _target_: gymnos.generative.image_generation.dcgan.trainer.DCGANTrainer
  rl.misc.random:
    num_train_timesteps: 1000
    num_test_episodes: 1
    log_interval: 1000
    _target_: gymnos.rl.misc.random.trainer.RandomTrainer
  rl.hybrid_optimization.td3:
    num_train_timesteps: ???
    verbose: true
    save_strategy: LAST
    eval_freq: 10000
    n_eval_episodes: 5
    max_num_train_episodes: null
    stop_training_reward_threshold: null
    log_interval: 100
    num_test_episodes: 1
    policy: MLP
    policy_kwargs: null
    learning_rate: 0.001
    buffer_size: 1000000
    learning_starts: 100
    batch_size: 100
    tau: 0.005
    discount_rate: 0.99
    train_freq:
    - 1
    - episode
    gradient_steps: -1
    optimize_memory_usage: false
    policy_delay: 2
    target_policy_noise: 0.2
    target_noise_clip: 0.5
    device: auto
    seed: 0
    _target_: gymnos.rl.hybrid_optimization.td3.trainer.TD3Trainer
  rl.hybrid_optimization.ddpg:
    num_train_timesteps: ???
    verbose: true
    save_strategy: LAST
    eval_freq: 10000
    n_eval_episodes: 5
    max_num_train_episodes: null
    stop_training_reward_threshold: null
    log_interval: 100
    num_test_episodes: 1
    policy: MLP
    num_envs: 1
    seed: 0
    policy_kwargs: null
    learning_rate: 0.001
    buffer_size: 1000000
    learning_starts: 100
    batch_size: 100
    tau: 0.005
    discount_rate: 0.99
    train_freq:
    - 1
    - episode
    gradient_steps: -1
    optimize_memory_usage: false
    device: auto
    _target_: gymnos.rl.hybrid_optimization.ddpg.trainer.DDPGTrainer
  rl.hybrid_optimization.sac:
    num_train_timesteps: ???
    verbose: true
    save_strategy: LAST
    eval_freq: 10000
    n_eval_episodes: 5
    max_num_train_episodes: null
    stop_training_reward_threshold: null
    log_interval: 100
    num_test_episodes: 1
    policy: MLP
    policy_kwargs: null
    learning_rate: 0.0003
    buffer_size: 1000000
    learning_starts: 100
    batch_size: 256
    tau: 0.005
    discount_rate: 0.99
    train_freq: 1
    gradient_steps: 1
    optimize_memory_usage: false
    entropy_coef: auto
    target_update_interval: 1
    use_sde: false
    sde_sample_freq: -1
    use_sde_at_warmup: false
    seed: 0
    device: auto
    _target_: gymnos.rl.hybrid_optimization.sac.trainer.SACTrainer
  rl.policy_optimization.a2c:
    num_train_timesteps: ???
    verbose: true
    save_strategy: LAST
    eval_freq: 10000
    n_eval_episodes: 5
    max_num_train_episodes: null
    stop_training_reward_threshold: null
    log_interval: 100
    num_test_episodes: 1
    policy_kwargs: null
    policy: MLP
    learning_rate: 0.001
    n_steps: 5
    discount_rate: 0.99
    gae_lambda: 1.0
    entropy_coef: 0.0
    value_coef: 0.5
    max_grad_norm: 0.5
    rms_prop_eps: 1.0e-05
    use_rms_prop: true
    use_sde: false
    sde_sample_freq: -1
    normalize_advantage: false
    num_envs: 1
    device: auto
    seed: 0
    _target_: gymnos.rl.policy_optimization.a2c.trainer.A2CTrainer
  rl.policy_optimization.ppo:
    num_train_timesteps: ???
    verbose: true
    save_strategy: LAST
    eval_freq: 10000
    n_eval_episodes: 5
    max_num_train_episodes: null
    stop_training_reward_threshold: null
    log_interval: 100
    num_test_episodes: 1
    policy: MLP
    num_envs: 1
    seed: 0
    policy_kwargs: null
    learning_rate: 0.0003
    n_steps: 2048
    batch_size: 64
    n_epochs: 10
    discount_rate: 0.99
    gae_lambda: 0.95
    clip_range: 0.2
    clip_range_value: null
    entropy_coef: 0.0
    value_coef: 0.5
    max_grad_norm: 0.5
    use_sde: false
    sde_sample_freq: -1
    target_kl: null
    device: auto
    _target_: gymnos.rl.policy_optimization.ppo.trainer.PPOTrainer
  rl.value_optimization.dqn:
    num_train_timesteps: ???
    verbose: true
    save_strategy: LAST
    eval_freq: 10000
    n_eval_episodes: 5
    max_num_train_episodes: null
    stop_training_reward_threshold: null
    log_interval: 100
    num_test_episodes: 1
    policy: MLP
    policy_kwargs: null
    learning_rate: 0.0001
    buffer_size: 1000000
    learning_starts: 50000
    batch_size: 32
    tau: 1.0
    discount_rate: 0.99
    train_freq: 4
    gradient_steps: 1
    optimize_memory_usage: false
    target_update_interval: 10000
    exploration_fraction: 0.1
    exploration_initial_eps: 1.0
    exploration_final_eps: 0.05
    max_grad_norm: 10
    seed: 0
    device: auto
    _target_: gymnos.rl.value_optimization.dqn.trainer.DQNTrainer
envs:
  dummy:
    _target_: gymnos.dummy.__env__.DummyEnv
  gym:
    id: ???
    _target_: gymnos.envs.gym.env.Gym
  atari:
    id: ???
    use_wrapper: true
    noop_max: 30
    frame_skip: 4
    screen_size: 84
    clip_reward: true
    terminal_on_life_loss: false
    frame_stack: 0
    include_actions: null
    _target_: gymnos.envs.atari.env.Atari
  box2d:
    id: ???
    _target_: gymnos.envs.box2d.env.Box2d
  ple:
    name: ???
    use_wrapper: true
    frame_stack: 0
    grayscale_obs: true
    _target_: gymnos.envs.ple.env.PLE
datasets:
  dummy:
    path: null
    _target_: gymnos.dummy.__dataset__.DummyDataset
  coins_detection:
    _target_: gymnos.datasets.coins_detection.dataset.CoinsDetection
  dogs_vs_cats:
    force_download: false
    max_workers: null
    _target_: gymnos.datasets.dogs_vs_cats.dataset.DogsVsCats
  raccoon_detection:
    _target_: gymnos.datasets.raccoon_detection.dataset.RaccoonDetection
  celeba_imgs:
    force_extract: false
    _target_: gymnos.datasets.celeba_imgs.dataset.CelebaImgs
  mnist_imgs:
    force_extract: false
    _target_: gymnos.datasets.mnist_imgs.dataset.MnistImgs
